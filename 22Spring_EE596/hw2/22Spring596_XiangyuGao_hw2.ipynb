{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CXQsfj5ze2_a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import lightgbm as lgb\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PAIZuNocfvj6"
   },
   "outputs": [],
   "source": [
    "# Load the csv files over here into pandas data frame\n",
    "# YOUR CODE HERE\n",
    "# 0.1\n",
    "def load_csv(file_name):\n",
    "  # Input: csv_file_name\n",
    "  # Output: pandas data frame\n",
    "    data = pd.read_csv(file_name)\n",
    "    print(data.info())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3129 entries, 0 to 3128\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Id                   3129 non-null   int64  \n",
      " 1   HR                   3020 non-null   float64\n",
      " 2   interval in seconds  3129 non-null   float64\n",
      " 3   NNRR                 3071 non-null   float64\n",
      " 4   AVNN                 3055 non-null   float64\n",
      " 5   SDNN                 3039 non-null   float64\n",
      " 6   RMSSD                3129 non-null   float64\n",
      " 7   pNN50                3129 non-null   float64\n",
      " 8   TP                   2910 non-null   float64\n",
      " 9   ULF                  3006 non-null   float64\n",
      " 10  VLF                  3033 non-null   float64\n",
      " 11  LF                   3033 non-null   float64\n",
      " 12  HF                   3033 non-null   float64\n",
      " 13  LF_HF                48 non-null     float64\n",
      " 14  stress               3129 non-null   float64\n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 366.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = load_csv('data_2-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9om9G-cfwWb"
   },
   "source": [
    "# Part 1 - Data cleaning, normalization and missing value fillup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "XbLj1nS9gG_Z"
   },
   "outputs": [],
   "source": [
    "def missing_filler1(df):\n",
    "  # Take input the raw data and fillup the missing values using first algorithm.\n",
    "  # YOUR CODE HERE\n",
    "    df_re = pd.DataFrame()\n",
    "    if 'stress' in df.columns:\n",
    "        for i in set(df['stress']):\n",
    "            df_i = df.where(df['stress'] == i)\n",
    "            df_i = df_i.replace(np.inf, np.nan)\n",
    "            df_i = df_i.dropna(axis=0,how='all')\n",
    "            df_i = df_i.fillna(df_i.mean())\n",
    "            df_re = pd.concat([df_re,df_i],axis = 0)\n",
    "    else:\n",
    "            df_i = df.replace(np.inf, np.nan)\n",
    "            df_i = df_i.dropna(axis=0,how='all')\n",
    "            df_i = df_i.fillna(df_i.mean())\n",
    "            df_re = pd.concat([df_re,df_i],axis = 0)\n",
    "    return df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_filler2(df):\n",
    "  # Take input the raw data and fillup the missing values using first algorithm.\n",
    "  # YOUR CODE HERE\n",
    "    df_re = pd.DataFrame()\n",
    "    if 'stress' in df.columns:\n",
    "        for i in set(df['stress']):\n",
    "            df_i = df.where(df['stress'] == i)\n",
    "            df_i = df_i.replace(np.inf, np.nan)\n",
    "            df_i = df_i.dropna(axis=0,how='all')\n",
    "            df_i = df_i.interpolate() \n",
    "            df_i = df_i.fillna(df_i.mean())\n",
    "            df_re = pd.concat([df_re,df_i],axis = 0)\n",
    "    else:\n",
    "            df_i = df.replace(np.inf, np.nan)\n",
    "            df_i = df_i.dropna(axis=0,how='all')\n",
    "            df_i = df_i.interpolate() \n",
    "            df_i = df_i.fillna(df_i.mean())\n",
    "            df_re = pd.concat([df_re,df_i],axis = 0)\n",
    "    return df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "OL7SYLfhgeMy"
   },
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "  # Take all the features as input, and do any data cleaning necessary.\n",
    "  # YOUR CODE HERE\n",
    "    df_re = pd.DataFrame()\n",
    "    df = df.drop('Id',axis = 1)\n",
    "    #data_ = data_[(np.abs(stats.zscore(data_))<3).all(axis = 1)]\n",
    "    if 'stress' in df.columns:\n",
    "        for i in set(df['stress']):\n",
    "            df_i = df.where(df['stress'] == i)\n",
    "            df_i = df_i.dropna(axis=0,how='all')\n",
    "            for i in df_i.columns:\n",
    "                if df_i.count()[i] < len(df_i)*0.2:\n",
    "                    del df_i[i]\n",
    "            df_re = pd.concat([df_re,df_i],axis = 0)\n",
    "    else:\n",
    "        for i in df.columns:\n",
    "            if df.count()[i] < len(df)*0.2:\n",
    "                del df[i]\n",
    "        df_re = pd.concat([df_re,df],axis = 0)\n",
    "    return df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "78nU0IK7f_2E"
   },
   "outputs": [],
   "source": [
    "def normalizer(df):\n",
    "  # Taken input the output of cleaning function, \n",
    "  #and perform data normalization independently for all the features.\n",
    "  # YOUR CODE HERE\n",
    "    data_std = df.copy()\n",
    "    std = StandardScaler()\n",
    "    if 'stress' in df.columns:\n",
    "        for col in df.columns.drop('stress'):\n",
    "            data_std[col] = std.fit_transform(data_std[col].values.reshape(-1,1))\n",
    "    else:\n",
    "        for col in df.columns:\n",
    "            data_std[col] = std.fit_transform(data_std[col].values.reshape(-1,1))\n",
    "    return data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>interval in seconds</th>\n",
       "      <th>NNRR</th>\n",
       "      <th>AVNN</th>\n",
       "      <th>SDNN</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>pNN50</th>\n",
       "      <th>TP</th>\n",
       "      <th>ULF</th>\n",
       "      <th>VLF</th>\n",
       "      <th>LF</th>\n",
       "      <th>HF</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.305989</td>\n",
       "      <td>-1.285923</td>\n",
       "      <td>1.346949</td>\n",
       "      <td>-1.296620</td>\n",
       "      <td>-1.669851</td>\n",
       "      <td>-1.610495</td>\n",
       "      <td>-1.369549</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>-0.948111</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276921</td>\n",
       "      <td>-1.298530</td>\n",
       "      <td>1.346949</td>\n",
       "      <td>-1.296620</td>\n",
       "      <td>-1.669851</td>\n",
       "      <td>-1.610495</td>\n",
       "      <td>-1.369549</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>-0.948111</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344172</td>\n",
       "      <td>-1.298530</td>\n",
       "      <td>1.346949</td>\n",
       "      <td>-1.296620</td>\n",
       "      <td>-1.669851</td>\n",
       "      <td>-1.610495</td>\n",
       "      <td>-1.369549</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>-0.948111</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.298530</td>\n",
       "      <td>1.346949</td>\n",
       "      <td>-1.296620</td>\n",
       "      <td>-1.669851</td>\n",
       "      <td>-1.610495</td>\n",
       "      <td>-1.369549</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>-0.948111</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481354</td>\n",
       "      <td>-1.208366</td>\n",
       "      <td>1.159974</td>\n",
       "      <td>-1.204084</td>\n",
       "      <td>-0.967631</td>\n",
       "      <td>-1.030283</td>\n",
       "      <td>-0.463398</td>\n",
       "      <td>-0.952790</td>\n",
       "      <td>-0.948111</td>\n",
       "      <td>-0.159366</td>\n",
       "      <td>5.072979</td>\n",
       "      <td>1.450954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-0.062251</td>\n",
       "      <td>-0.159776</td>\n",
       "      <td>-0.059917</td>\n",
       "      <td>-0.122519</td>\n",
       "      <td>-0.121686</td>\n",
       "      <td>-0.320323</td>\n",
       "      <td>-0.303772</td>\n",
       "      <td>-0.289243</td>\n",
       "      <td>-0.229110</td>\n",
       "      <td>-0.200357</td>\n",
       "      <td>-0.189888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>-0.285291</td>\n",
       "      <td>-0.062251</td>\n",
       "      <td>-0.159776</td>\n",
       "      <td>-0.059917</td>\n",
       "      <td>-0.122519</td>\n",
       "      <td>-0.121686</td>\n",
       "      <td>-0.320323</td>\n",
       "      <td>-0.311961</td>\n",
       "      <td>-0.297438</td>\n",
       "      <td>-0.229110</td>\n",
       "      <td>-0.200357</td>\n",
       "      <td>-0.189888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>0.160154</td>\n",
       "      <td>-0.589647</td>\n",
       "      <td>0.546033</td>\n",
       "      <td>-0.587114</td>\n",
       "      <td>-0.819685</td>\n",
       "      <td>-0.796746</td>\n",
       "      <td>-0.397097</td>\n",
       "      <td>-0.751806</td>\n",
       "      <td>-0.737600</td>\n",
       "      <td>-0.229110</td>\n",
       "      <td>-0.200357</td>\n",
       "      <td>-0.189888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>0.248917</td>\n",
       "      <td>-0.589647</td>\n",
       "      <td>0.546033</td>\n",
       "      <td>-0.587114</td>\n",
       "      <td>-0.819685</td>\n",
       "      <td>-0.796746</td>\n",
       "      <td>-0.397097</td>\n",
       "      <td>-0.751248</td>\n",
       "      <td>-0.737043</td>\n",
       "      <td>-0.229110</td>\n",
       "      <td>-0.200357</td>\n",
       "      <td>-0.189888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>0.108838</td>\n",
       "      <td>-0.589647</td>\n",
       "      <td>0.546033</td>\n",
       "      <td>-0.587114</td>\n",
       "      <td>-0.819685</td>\n",
       "      <td>-0.796746</td>\n",
       "      <td>-0.397097</td>\n",
       "      <td>-0.754512</td>\n",
       "      <td>-0.740308</td>\n",
       "      <td>-0.229110</td>\n",
       "      <td>-0.200357</td>\n",
       "      <td>-0.189888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3129 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HR  interval in seconds      NNRR      AVNN      SDNN     RMSSD  \\\n",
       "0     1.305989            -1.285923  1.346949 -1.296620 -1.669851 -1.610495   \n",
       "1     0.276921            -1.298530  1.346949 -1.296620 -1.669851 -1.610495   \n",
       "2     0.344172            -1.298530  1.346949 -1.296620 -1.669851 -1.610495   \n",
       "3     0.497708            -1.298530  1.346949 -1.296620 -1.669851 -1.610495   \n",
       "4     0.481354            -1.208366  1.159974 -1.204084 -0.967631 -1.030283   \n",
       "...        ...                  ...       ...       ...       ...       ...   \n",
       "3071 -0.164525            -0.062251 -0.159776 -0.059917 -0.122519 -0.121686   \n",
       "3072 -0.285291            -0.062251 -0.159776 -0.059917 -0.122519 -0.121686   \n",
       "3073  0.160154            -0.589647  0.546033 -0.587114 -0.819685 -0.796746   \n",
       "3074  0.248917            -0.589647  0.546033 -0.587114 -0.819685 -0.796746   \n",
       "3075  0.108838            -0.589647  0.546033 -0.587114 -0.819685 -0.796746   \n",
       "\n",
       "         pNN50        TP       ULF       VLF        LF        HF  stress  \n",
       "0    -1.369549 -0.009374 -0.948111 -0.006073  0.068880  0.042274     0.0  \n",
       "1    -1.369549 -0.009374 -0.948111 -0.006073  0.068880  0.042274     0.0  \n",
       "2    -1.369549 -0.009374 -0.948111 -0.006073  0.068880  0.042274     0.0  \n",
       "3    -1.369549 -0.009374 -0.948111 -0.006073  0.068880  0.042274     0.0  \n",
       "4    -0.463398 -0.952790 -0.948111 -0.159366  5.072979  1.450954     0.0  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3071 -0.320323 -0.303772 -0.289243 -0.229110 -0.200357 -0.189888     2.0  \n",
       "3072 -0.320323 -0.311961 -0.297438 -0.229110 -0.200357 -0.189888     2.0  \n",
       "3073 -0.397097 -0.751806 -0.737600 -0.229110 -0.200357 -0.189888     2.0  \n",
       "3074 -0.397097 -0.751248 -0.737043 -0.229110 -0.200357 -0.189888     2.0  \n",
       "3075 -0.397097 -0.754512 -0.740308 -0.229110 -0.200357 -0.189888     2.0  \n",
       "\n",
       "[3129 rows x 13 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = cleaning(data)\n",
    "data1 = missing_filler2(data1)\n",
    "data1 = normalizer(data1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09lUBNIAgf7e"
   },
   "source": [
    "# Part 2 - Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VM4wDJQkgreS"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, val and test sets.\n",
    "# 2.0\n",
    "X = np.array(data1.drop(['stress'],axis = 1))\n",
    "y = np.array(data1['stress'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MCKyvlx4gv2R"
   },
   "outputs": [],
   "source": [
    "# Code for different models used.\n",
    "\n",
    "def decisiontree(X_train,y_train,X_test,y_test):\n",
    "  # You can use the sci-kit learn solver but capture any other hyper-parameter settings\n",
    "  # or model settings in this method\n",
    "  # YOUR CODE HERE\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=6,min_weight_fraction_leaf=0.001)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print('Decision Tree')\n",
    "    print('train score:', accuracy_score(y_train, y_train_pred))\n",
    "    print('test score:', accuracy_score(y_test, y_test_pred))\n",
    "    return y_train_pred, clf\n",
    "\n",
    "def logisticregression(X_train,y_train,X_test,y_test):\n",
    "  # You can use the sci-kit learn solver but capture any other hyper-parameter settings\n",
    "  # or model settings in this method\n",
    "  # YOUR CODE HERE\n",
    "    lr = LogisticRegression(tol = 1e-5,max_iter = 150)\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_train_pred = lr.predict(X_train)\n",
    "    y_test_pred = lr.predict(X_test)\n",
    "    print('Logistic Regression')\n",
    "    print('train score:', accuracy_score(y_train, y_train_pred))\n",
    "    print('test score:', accuracy_score(y_test, y_test_pred))\n",
    "    return y_train_pred,lr\n",
    "\n",
    "def randomforest(X_train, y_train,X_test,y_test):\n",
    "  # You can use the sci-kit learn solver but capture any other hyper-parameter settings\n",
    "  # or model settings in this method\n",
    "  # YOUR CODE HERE\n",
    "    acc = 0\n",
    "    model = None\n",
    "    rf = RandomForestClassifier(\n",
    "         criterion='entropy',\n",
    "            n_estimators=54, \n",
    "            max_depth=47,\n",
    "            min_weight_fraction_leaf=0.005\n",
    "            )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    print('Random Forest')\n",
    "    print('train score:', accuracy_score(y_train, y_train_pred))\n",
    "    print('test score:', accuracy_score(y_test, y_test_pred))\n",
    "    return y_train_pred,rf\n",
    "\n",
    "def MLP(X_train, y_train,X_test,y_test):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=25000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_train_pred = mlp.predict(X_train)\n",
    "    y_test_pred = mlp.predict(X_test)\n",
    "    print('MLP')\n",
    "    print('train score:', accuracy_score(y_train, y_train_pred))\n",
    "    print('test score:', accuracy_score(y_test, y_test_pred))\n",
    "    return y_train_pred,mlp\n",
    "\n",
    "def NN(X_train, y_train,X_test,y_test):\n",
    "    y_train_c = to_categorical(y_train)\n",
    "    y_test_c = to_categorical(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(X_train.shape[1], )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(y_train_c.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(adam_v2.Adam(), categorical_crossentropy, ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train_c, batch_size=128, epochs=5000, verbose=0)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    #eval_on_show(X_train, y_train, y_train_pred, X_test, y_test, y_test_pred)\n",
    "    y_train_pred_1 = [i.index(max(i)) for i in y_train_pred.tolist()]\n",
    "    y_test_pred_1 = [i.index(max(i)) for i in y_test_pred.tolist()]\n",
    "    print('Neural Network')\n",
    "    print('train score:', accuracy_score(y_train, y_train_pred_1))\n",
    "    print('test score:', accuracy_score(y_test, y_test_pred_1))\n",
    "    return y_train_pred_1,model\n",
    "# Please also rename the model functions to reflect what it represents.\n",
    "# Discuss about the hyper-parameter/model settings in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'max_depth': 47, 'n_estimators': 54}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "estimator=  RandomForestClassifier(criterion='entropy',\n",
    "                                    min_weight_fraction_leaf=0.005)\n",
    "param_grid = {'max_depth': range(10,100),\n",
    "              'n_estimators': range(50,100)}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid)\n",
    "gbm.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "train score: 0.491410307630843\n",
      "test score: 0.4424920127795527\n",
      "Random Forest\n",
      "train score: 0.6388333999200959\n",
      "test score: 0.5095846645367412\n",
      "Decision Tree\n",
      "train score: 0.564522572912505\n",
      "test score: 0.49201277955271566\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr,LR_model = logisticregression(X_train,y_train,X_test,y_test)\n",
    "y_pred_RF,RF_model = randomforest(X_train,y_train,X_test,y_test)\n",
    "y_pred_DT,DT_model = decisiontree(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yn2M8HOIhPGi"
   },
   "outputs": [],
   "source": [
    "# Create function which calculates F1score, precision, recall and accuracy score for true and predicted labels.\n",
    "def metrics(y_pred, y_test,name):\n",
    "\n",
    "  # Takes input the predicted and true labels.\n",
    "  # Your code here for precision, recall, F1score, accuracy\n",
    "  # You can call this code to compute metrics for your models\n",
    "    con_matrix = confusion_matrix(y_test, y_pred)\n",
    "    cla_report = classification_report(y_test, y_pred)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    f1_score_ = f1_score(y_test, y_pred,average='weighted')\n",
    "    print(name)\n",
    "    print('confusion_matrix:')\n",
    "    print(con_matrix)\n",
    "    print('---------------------------------')\n",
    "    print('classification_report:')\n",
    "    print(cla_report)\n",
    "    print('---------------------------------')\n",
    "    print('accuracy_score:')\n",
    "    print(acc_score)\n",
    "    print('---------------------------------')\n",
    "    print('f1_score:')\n",
    "    print(f1_score_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "confusion_matrix:\n",
      "[[ 310  361   14]\n",
      " [ 117 1067   29]\n",
      " [  33  526   46]]\n",
      "---------------------------------\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.45      0.54       685\n",
      "         1.0       0.55      0.88      0.67      1213\n",
      "         2.0       0.52      0.08      0.13       605\n",
      "\n",
      "    accuracy                           0.57      2503\n",
      "   macro avg       0.58      0.47      0.45      2503\n",
      "weighted avg       0.57      0.57      0.51      2503\n",
      "\n",
      "---------------------------------\n",
      "accuracy_score:\n",
      "0.5685177786656013\n",
      "---------------------------------\n",
      "f1_score:\n",
      "0.5067786811038061\n"
     ]
    }
   ],
   "source": [
    "metrics(y_pred_lr, y_train,'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "confusion_matrix:\n",
      "[[ 310  361   14]\n",
      " [ 117 1067   29]\n",
      " [  33  526   46]]\n",
      "---------------------------------\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.45      0.54       685\n",
      "         1.0       0.55      0.88      0.67      1213\n",
      "         2.0       0.52      0.08      0.13       605\n",
      "\n",
      "    accuracy                           0.57      2503\n",
      "   macro avg       0.58      0.47      0.45      2503\n",
      "weighted avg       0.57      0.57      0.51      2503\n",
      "\n",
      "---------------------------------\n",
      "accuracy_score:\n",
      "0.5685177786656013\n",
      "---------------------------------\n",
      "f1_score:\n",
      "0.5067786811038061\n"
     ]
    }
   ],
   "source": [
    "metrics(y_pred_lr, y_train,'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "confusion_matrix:\n",
      "[[ 459  208   18]\n",
      " [  77 1060   76]\n",
      " [  24  332  249]]\n",
      "---------------------------------\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.67      0.74       685\n",
      "         1.0       0.66      0.87      0.75      1213\n",
      "         2.0       0.73      0.41      0.53       605\n",
      "\n",
      "    accuracy                           0.71      2503\n",
      "   macro avg       0.74      0.65      0.67      2503\n",
      "weighted avg       0.72      0.71      0.69      2503\n",
      "\n",
      "---------------------------------\n",
      "accuracy_score:\n",
      "0.706352377147423\n",
      "---------------------------------\n",
      "f1_score:\n",
      "0.6939954927655633\n"
     ]
    }
   ],
   "source": [
    "metrics(y_pred_RF, y_train,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Prediction\n",
    "data_kaggle = pd.read_csv('kaggle_2.csv')\n",
    "data_kaggle = cleaning(data_kaggle)\n",
    "data_kaggle = missing_filler1(data_kaggle)\n",
    "data_kaggle = normalizer(data_kaggle)\n",
    "X_kaggle = np.array(data_kaggle)\n",
    "y_kaggle = RF_model.predict(X_kaggle)\n",
    "#y_kaggle = [float(i.index(max(i))) for i in y_kaggle.tolist()]\n",
    "out_file = pd.DataFrame(range(0,1000),columns = ['Id'])\n",
    "out_file['stress'] = y_kaggle\n",
    "out_file['stress'].astype(float)\n",
    "\n",
    "out_file.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1JgEU62iARH"
   },
   "source": [
    "# Part 3 - Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data1.drop(['stress'],axis = 1))\n",
    "y = np.array(data1['stress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into using suitable functions from sklearn. Explain your code and findings clearly in the report document.\n",
    "# YOUR CODE HERE\n",
    "# 3.1\n",
    "\n",
    "def FeatureImportance(X,y,dataset,k,d_type='ETC'): # d_type:'ETC' or 'MIC'\n",
    "  # Your code can based on measures of information gain or other feature selection methods\n",
    "  # Input: k - Number of features to pick\n",
    "  # Output should be a ranked list of features\n",
    "    d = {}\n",
    "    if d_type == 'MIC':\n",
    "        result = mutual_info_classif(X, y, discrete_features= False)\n",
    "    elif d_type == 'ETC':\n",
    "        forest = ExtraTreesClassifier(n_estimators=250, random_state=0).fit(X,y)\n",
    "        result = forest.feature_importances_\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    dataset = list(dataset.columns)\n",
    "    dataset.remove('stress')\n",
    "    \n",
    "    for i in range(len(X[1])):\n",
    "        d[dataset[i]] = result[i]\n",
    "    re = sorted(d.items(),key = lambda v:v[1])\n",
    "    re.reverse()\n",
    "    \n",
    "    if k > len(X[1]): \n",
    "        k = len(X[1])\n",
    "    if not k:\n",
    "        return False\n",
    "    \n",
    "    indices = np.argsort(result)[::-1]\n",
    "    plt.bar(range(12), result[indices])\n",
    "    plt.xticks(range(X.shape[1]), [dataset[i] for i in indices])\n",
    "    plt.show()\n",
    "    \n",
    "    return re[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('interval in seconds', 0.1769182973291652),\n",
       " ('AVNN', 0.16680977435470923),\n",
       " ('SDNN', 0.14888458544810512),\n",
       " ('RMSSD', 0.14199441513463085),\n",
       " ('NNRR', 0.0834642629323572)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureImportance(X,y,data1,k = 5,d_type='MIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('HR', 0.20930905840371986),\n",
       " ('ULF', 0.20439928666654184),\n",
       " ('TP', 0.20429202860938592),\n",
       " ('interval in seconds', 0.0777850301111131),\n",
       " ('AVNN', 0.07774884755478108)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureImportance(X,y,data1,k = 5,d_type='ETC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kDYIvo2bk7UR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importances: [ 0.04792332  0.03738019  0.00415335  0.03769968  0.02779553  0.01501597\n",
      "  0.00319489  0.02939297  0.0284345  -0.0086262   0.00095847 -0.00255591]\n",
      "feature importances std: [0.0109748  0.01013339 0.00511182 0.01003215 0.00411633 0.00576852\n",
      " 0.0049495  0.00594284 0.00592563 0.00127796 0.00162908 0.00127796]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0479\n",
       "                \n",
       "                    &plusmn; 0.0219\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0377\n",
       "                \n",
       "                    &plusmn; 0.0201\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AVNN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0374\n",
       "                \n",
       "                    &plusmn; 0.0203\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                interval in seconds\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0294\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0284\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ULF\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0278\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDNN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0150\n",
       "                \n",
       "                    &plusmn; 0.0115\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RMSSD\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                NNRR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                pNN50\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LF\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.43%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0026\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HF\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0086\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VLF\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FeatureImportanceForPairs(model):\n",
    "  # Find the best pairs of features which are useful for making the prediction.\n",
    "  # HINT: Can be done in a model agnostic way through pair generation and ranking.\n",
    "  # YOUR CODE HERE\n",
    "    perm = PermutationImportance(model).fit(X_test, y_test)\n",
    "    print('feature importances:',perm.feature_importances_)\n",
    "    print('feature importances std:',perm.feature_importances_std_)\n",
    "    return eli5.show_weights(perm,feature_names=data1.columns.drop('stress').tolist())\n",
    "\n",
    "FeatureImportanceForPairs(RF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Pair: HR AVNN\n",
      "Random Forest\n",
      "train score: 0.6404314822213344\n",
      "test score: 0.5111821086261981\n",
      "----------------------------------\n",
      "Feature Pair: HR interval in seconds\n",
      "Random Forest\n",
      "train score: 0.6308429884139033\n",
      "test score: 0.5271565495207667\n",
      "----------------------------------\n",
      "Feature Pair: HR TP\n",
      "Random Forest\n",
      "train score: 0.630043947263284\n",
      "test score: 0.5447284345047924\n",
      "----------------------------------\n",
      "Feature Pair: HR ULF\n",
      "Random Forest\n",
      "train score: 0.6448262085497403\n",
      "test score: 0.5207667731629393\n",
      "----------------------------------\n",
      "Feature Pair: interval in seconds AVNN\n",
      "Random Forest\n",
      "train score: 0.6456252497003596\n",
      "test score: 0.5159744408945687\n",
      "----------------------------------\n",
      "Feature Pair: interval in seconds TP\n",
      "Random Forest\n",
      "train score: 0.6372353176188573\n",
      "test score: 0.5527156549520766\n",
      "----------------------------------\n",
      "Feature Pair: interval in seconds ULF\n",
      "Random Forest\n",
      "train score: 0.6256492209348782\n",
      "test score: 0.5670926517571885\n",
      "----------------------------------\n",
      "Feature Pair: ULF AVNN\n",
      "Random Forest\n",
      "train score: 0.6452257291250499\n",
      "test score: 0.5\n",
      "----------------------------------\n",
      "Feature Pair: ULF TP\n",
      "Random Forest\n",
      "train score: 0.6284458649620456\n",
      "test score: 0.5591054313099042\n",
      "----------------------------------\n",
      "Feature Pair: AVNN TP\n",
      "Random Forest\n",
      "train score: 0.6404314822213344\n",
      "test score: 0.5047923322683706\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "top5 = ['HR','AVNN','interval in seconds','TP','ULF']\n",
    "while top5:\n",
    "    for i in top5:\n",
    "        top5.remove(i)\n",
    "        for j in top5:\n",
    "            data_tem = data1[i] + data1[j]\n",
    "            X_tem = np.array(data_tem)\n",
    "            y_tem = np.array(data1['stress'])\n",
    "            X_train_tem, X_test_tem, y_train_tem, y_test_tem = train_test_split(X, y, test_size = 0.2)\n",
    "            print('Feature Pair:',i,j)\n",
    "            randomforest(X_train_tem,y_train_tem,X_test_tem,y_test_tem)\n",
    "            print('----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prog_assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
